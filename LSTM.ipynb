{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b55e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b429bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"F:/ML/LSTM_Next_word_Prediction/RNN.txt\" , 'r', encoding='utf-8') as file:\n",
    "    rnn=file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15f9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c735342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(filters=filters)\n",
    "#A TensorFlow tokenizer is a tool used to split text into smaller units called tokens\n",
    "tokenizer.fit_on_texts([rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a3baf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': None,\n",
       " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
       " 'lower': True,\n",
       " 'split': ' ',\n",
       " 'char_level': False,\n",
       " 'oov_token': None,\n",
       " 'document_count': 1,\n",
       " 'word_counts': '{\"recurrent\": 2, \"neural\": 2, \"networks\": 1, \"rnns\": 2, \"are\": 2, \"a\": 5, \"type\": 1, \"of\": 5, \"network\": 4, \"designed\": 1, \"to\": 8, \"process\": 1, \"sequential\": 1, \"data\": 2, \"such\": 1, \"as\": 4, \"text\": 1, \"or\": 1, \"time\": 2, \"series\": 1, \"information\": 4, \"in\": 4, \"an\": 1, \"rnn\": 2, \"each\": 1, \"output\": 1, \"depends\": 1, \"not\": 1, \"just\": 1, \"on\": 3, \"the\": 11, \"current\": 1, \"input\": 1, \"but\": 1, \"also\": 1, \"previous\": 1, \"hidden\": 1, \"state\": 1, \"which\": 1, \"allows\": 1, \"retain\": 3, \"some\": 1, \"memory\": 3, \"earlier\": 3, \"inputs\": 3, \"however\": 1, \"standard\": 1, \"suffer\": 1, \"from\": 4, \"limitation\": 2, \"known\": 1, \"short\": 2, \"term\": 4, \"this\": 4, \"means\": 1, \"that\": 1, \"while\": 1, \"they\": 3, \"can\": 1, \"remember\": 1, \"recent\": 1, \"reasonably\": 1, \"well\": 1, \"struggle\": 1, \"much\": 1, \"sequence\": 2, \"becomes\": 1, \"problem\": 2, \"when\": 1, \"long\": 3, \"dependencies\": 1, \"important\\\\u2014for\": 1, \"example\": 1, \"remembering\": 1, \"subject\": 1, \"sentence\": 1, \"correctly\": 1, \"predict\": 1, \"final\": 1, \"word\": 1, \"root\": 1, \"issue\": 1, \"lies\": 1, \"vanishing\": 1, \"gradient\": 1, \"where\": 1, \"gradients\": 1, \"used\": 1, \"training\": 1, \"become\": 1, \"extremely\": 1, \"small\": 1, \"propagate\": 1, \"backward\": 1, \"through\": 1, \"many\": 1, \"steps\": 1, \"effectively\": 1, \"preventing\": 1, \"early\": 1, \"layers\": 1, \"learning\": 1, \"result\": 1, \"fades\": 1, \"away\": 1, \"and\": 3, \"fails\": 1, \"capture\": 1, \"context\": 1, \"overcome\": 1, \"advanced\": 1, \"architectures\": 2, \"like\": 1, \"lstm\": 1, \"gated\": 1, \"unit\": 1, \"gru\": 1, \"were\": 1, \"developed\": 1, \"these\": 1, \"use\": 1, \"gating\": 1, \"mechanisms\": 1, \"control\": 1, \"flow\": 1, \"allowing\": 1, \"important\": 1, \"over\": 1, \"longer\": 1, \"periods\": 1, \"significantly\": 1, \"improving\": 1, \"performance\": 1, \"complex\": 1, \"based\": 1, \"tasks\": 1}',\n",
       " 'word_docs': '{\"or\": 1, \"a\": 1, \"allowing\": 1, \"steps\": 1, \"output\": 1, \"developed\": 1, \"sequential\": 1, \"word\": 1, \"root\": 1, \"standard\": 1, \"advanced\": 1, \"much\": 1, \"unit\": 1, \"important\": 1, \"means\": 1, \"not\": 1, \"use\": 1, \"network\": 1, \"many\": 1, \"input\": 1, \"these\": 1, \"that\": 1, \"architectures\": 1, \"just\": 1, \"designed\": 1, \"state\": 1, \"preventing\": 1, \"remember\": 1, \"reasonably\": 1, \"earlier\": 1, \"networks\": 1, \"struggle\": 1, \"final\": 1, \"over\": 1, \"sentence\": 1, \"through\": 1, \"gated\": 1, \"layers\": 1, \"vanishing\": 1, \"complex\": 1, \"correctly\": 1, \"gradient\": 1, \"lies\": 1, \"example\": 1, \"can\": 1, \"when\": 1, \"become\": 1, \"based\": 1, \"rnns\": 1, \"problem\": 1, \"gradients\": 1, \"they\": 1, \"hidden\": 1, \"significantly\": 1, \"also\": 1, \"such\": 1, \"allows\": 1, \"issue\": 1, \"known\": 1, \"tasks\": 1, \"capture\": 1, \"suffer\": 1, \"result\": 1, \"periods\": 1, \"series\": 1, \"information\": 1, \"short\": 1, \"context\": 1, \"important\\\\u2014for\": 1, \"gating\": 1, \"type\": 1, \"were\": 1, \"flow\": 1, \"like\": 1, \"current\": 1, \"away\": 1, \"gru\": 1, \"propagate\": 1, \"backward\": 1, \"data\": 1, \"control\": 1, \"early\": 1, \"effectively\": 1, \"text\": 1, \"from\": 1, \"as\": 1, \"neural\": 1, \"sequence\": 1, \"this\": 1, \"long\": 1, \"while\": 1, \"mechanisms\": 1, \"rnn\": 1, \"becomes\": 1, \"memory\": 1, \"depends\": 1, \"of\": 1, \"time\": 1, \"and\": 1, \"retain\": 1, \"each\": 1, \"dependencies\": 1, \"overcome\": 1, \"longer\": 1, \"on\": 1, \"are\": 1, \"training\": 1, \"fades\": 1, \"performance\": 1, \"subject\": 1, \"improving\": 1, \"but\": 1, \"learning\": 1, \"fails\": 1, \"predict\": 1, \"where\": 1, \"the\": 1, \"to\": 1, \"limitation\": 1, \"term\": 1, \"however\": 1, \"inputs\": 1, \"lstm\": 1, \"recurrent\": 1, \"process\": 1, \"some\": 1, \"previous\": 1, \"small\": 1, \"recent\": 1, \"which\": 1, \"well\": 1, \"an\": 1, \"remembering\": 1, \"extremely\": 1, \"used\": 1, \"in\": 1}',\n",
       " 'index_docs': '{\"39\": 1, \"3\": 1, \"126\": 1, \"99\": 1, \"43\": 1, \"119\": 1, \"36\": 1, \"82\": 1, \"83\": 1, \"58\": 1, \"112\": 1, \"70\": 1, \"116\": 1, \"127\": 1, \"61\": 1, \"45\": 1, \"121\": 1, \"5\": 1, \"98\": 1, \"48\": 1, \"120\": 1, \"62\": 1, \"31\": 1, \"46\": 1, \"34\": 1, \"53\": 1, \"101\": 1, \"65\": 1, \"67\": 1, \"15\": 1, \"32\": 1, \"69\": 1, \"81\": 1, \"128\": 1, \"78\": 1, \"97\": 1, \"115\": 1, \"103\": 1, \"86\": 1, \"134\": 1, \"79\": 1, \"87\": 1, \"85\": 1, \"75\": 1, \"64\": 1, \"72\": 1, \"92\": 1, \"135\": 1, \"22\": 1, \"30\": 1, \"89\": 1, \"17\": 1, \"52\": 1, \"131\": 1, \"50\": 1, \"37\": 1, \"55\": 1, \"84\": 1, \"60\": 1, \"136\": 1, \"109\": 1, \"59\": 1, \"105\": 1, \"130\": 1, \"40\": 1, \"7\": 1, \"28\": 1, \"110\": 1, \"74\": 1, \"122\": 1, \"33\": 1, \"118\": 1, \"125\": 1, \"113\": 1, \"47\": 1, \"107\": 1, \"117\": 1, \"95\": 1, \"96\": 1, \"24\": 1, \"124\": 1, \"102\": 1, \"100\": 1, \"38\": 1, \"9\": 1, \"6\": 1, \"21\": 1, \"29\": 1, \"11\": 1, \"18\": 1, \"63\": 1, \"123\": 1, \"26\": 1, \"71\": 1, \"14\": 1, \"44\": 1, \"4\": 1, \"25\": 1, \"19\": 1, \"13\": 1, \"42\": 1, \"73\": 1, \"111\": 1, \"129\": 1, \"12\": 1, \"23\": 1, \"91\": 1, \"106\": 1, \"133\": 1, \"77\": 1, \"132\": 1, \"49\": 1, \"104\": 1, \"108\": 1, \"80\": 1, \"88\": 1, \"1\": 1, \"2\": 1, \"27\": 1, \"10\": 1, \"57\": 1, \"16\": 1, \"114\": 1, \"20\": 1, \"35\": 1, \"56\": 1, \"51\": 1, \"94\": 1, \"66\": 1, \"54\": 1, \"68\": 1, \"41\": 1, \"76\": 1, \"93\": 1, \"90\": 1, \"8\": 1}',\n",
       " 'index_word': '{\"1\": \"the\", \"2\": \"to\", \"3\": \"a\", \"4\": \"of\", \"5\": \"network\", \"6\": \"as\", \"7\": \"information\", \"8\": \"in\", \"9\": \"from\", \"10\": \"term\", \"11\": \"this\", \"12\": \"on\", \"13\": \"retain\", \"14\": \"memory\", \"15\": \"earlier\", \"16\": \"inputs\", \"17\": \"they\", \"18\": \"long\", \"19\": \"and\", \"20\": \"recurrent\", \"21\": \"neural\", \"22\": \"rnns\", \"23\": \"are\", \"24\": \"data\", \"25\": \"time\", \"26\": \"rnn\", \"27\": \"limitation\", \"28\": \"short\", \"29\": \"sequence\", \"30\": \"problem\", \"31\": \"architectures\", \"32\": \"networks\", \"33\": \"type\", \"34\": \"designed\", \"35\": \"process\", \"36\": \"sequential\", \"37\": \"such\", \"38\": \"text\", \"39\": \"or\", \"40\": \"series\", \"41\": \"an\", \"42\": \"each\", \"43\": \"output\", \"44\": \"depends\", \"45\": \"not\", \"46\": \"just\", \"47\": \"current\", \"48\": \"input\", \"49\": \"but\", \"50\": \"also\", \"51\": \"previous\", \"52\": \"hidden\", \"53\": \"state\", \"54\": \"which\", \"55\": \"allows\", \"56\": \"some\", \"57\": \"however\", \"58\": \"standard\", \"59\": \"suffer\", \"60\": \"known\", \"61\": \"means\", \"62\": \"that\", \"63\": \"while\", \"64\": \"can\", \"65\": \"remember\", \"66\": \"recent\", \"67\": \"reasonably\", \"68\": \"well\", \"69\": \"struggle\", \"70\": \"much\", \"71\": \"becomes\", \"72\": \"when\", \"73\": \"dependencies\", \"74\": \"important\\\\u2014for\", \"75\": \"example\", \"76\": \"remembering\", \"77\": \"subject\", \"78\": \"sentence\", \"79\": \"correctly\", \"80\": \"predict\", \"81\": \"final\", \"82\": \"word\", \"83\": \"root\", \"84\": \"issue\", \"85\": \"lies\", \"86\": \"vanishing\", \"87\": \"gradient\", \"88\": \"where\", \"89\": \"gradients\", \"90\": \"used\", \"91\": \"training\", \"92\": \"become\", \"93\": \"extremely\", \"94\": \"small\", \"95\": \"propagate\", \"96\": \"backward\", \"97\": \"through\", \"98\": \"many\", \"99\": \"steps\", \"100\": \"effectively\", \"101\": \"preventing\", \"102\": \"early\", \"103\": \"layers\", \"104\": \"learning\", \"105\": \"result\", \"106\": \"fades\", \"107\": \"away\", \"108\": \"fails\", \"109\": \"capture\", \"110\": \"context\", \"111\": \"overcome\", \"112\": \"advanced\", \"113\": \"like\", \"114\": \"lstm\", \"115\": \"gated\", \"116\": \"unit\", \"117\": \"gru\", \"118\": \"were\", \"119\": \"developed\", \"120\": \"these\", \"121\": \"use\", \"122\": \"gating\", \"123\": \"mechanisms\", \"124\": \"control\", \"125\": \"flow\", \"126\": \"allowing\", \"127\": \"important\", \"128\": \"over\", \"129\": \"longer\", \"130\": \"periods\", \"131\": \"significantly\", \"132\": \"improving\", \"133\": \"performance\", \"134\": \"complex\", \"135\": \"based\", \"136\": \"tasks\"}',\n",
       " 'word_index': '{\"the\": 1, \"to\": 2, \"a\": 3, \"of\": 4, \"network\": 5, \"as\": 6, \"information\": 7, \"in\": 8, \"from\": 9, \"term\": 10, \"this\": 11, \"on\": 12, \"retain\": 13, \"memory\": 14, \"earlier\": 15, \"inputs\": 16, \"they\": 17, \"long\": 18, \"and\": 19, \"recurrent\": 20, \"neural\": 21, \"rnns\": 22, \"are\": 23, \"data\": 24, \"time\": 25, \"rnn\": 26, \"limitation\": 27, \"short\": 28, \"sequence\": 29, \"problem\": 30, \"architectures\": 31, \"networks\": 32, \"type\": 33, \"designed\": 34, \"process\": 35, \"sequential\": 36, \"such\": 37, \"text\": 38, \"or\": 39, \"series\": 40, \"an\": 41, \"each\": 42, \"output\": 43, \"depends\": 44, \"not\": 45, \"just\": 46, \"current\": 47, \"input\": 48, \"but\": 49, \"also\": 50, \"previous\": 51, \"hidden\": 52, \"state\": 53, \"which\": 54, \"allows\": 55, \"some\": 56, \"however\": 57, \"standard\": 58, \"suffer\": 59, \"known\": 60, \"means\": 61, \"that\": 62, \"while\": 63, \"can\": 64, \"remember\": 65, \"recent\": 66, \"reasonably\": 67, \"well\": 68, \"struggle\": 69, \"much\": 70, \"becomes\": 71, \"when\": 72, \"dependencies\": 73, \"important\\\\u2014for\": 74, \"example\": 75, \"remembering\": 76, \"subject\": 77, \"sentence\": 78, \"correctly\": 79, \"predict\": 80, \"final\": 81, \"word\": 82, \"root\": 83, \"issue\": 84, \"lies\": 85, \"vanishing\": 86, \"gradient\": 87, \"where\": 88, \"gradients\": 89, \"used\": 90, \"training\": 91, \"become\": 92, \"extremely\": 93, \"small\": 94, \"propagate\": 95, \"backward\": 96, \"through\": 97, \"many\": 98, \"steps\": 99, \"effectively\": 100, \"preventing\": 101, \"early\": 102, \"layers\": 103, \"learning\": 104, \"result\": 105, \"fades\": 106, \"away\": 107, \"fails\": 108, \"capture\": 109, \"context\": 110, \"overcome\": 111, \"advanced\": 112, \"like\": 113, \"lstm\": 114, \"gated\": 115, \"unit\": 116, \"gru\": 117, \"were\": 118, \"developed\": 119, \"these\": 120, \"use\": 121, \"gating\": 122, \"mechanisms\": 123, \"control\": 124, \"flow\": 125, \"allowing\": 126, \"important\": 127, \"over\": 128, \"longer\": 129, \"periods\": 130, \"significantly\": 131, \"improving\": 132, \"performance\": 133, \"complex\": 134, \"based\": 135, \"tasks\": 136}'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_config() # Shows word counts, indices, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "458b2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'a': 3,\n",
       " 'of': 4,\n",
       " 'network': 5,\n",
       " 'as': 6,\n",
       " 'information': 7,\n",
       " 'in': 8,\n",
       " 'from': 9,\n",
       " 'term': 10,\n",
       " 'this': 11,\n",
       " 'on': 12,\n",
       " 'retain': 13,\n",
       " 'memory': 14,\n",
       " 'earlier': 15,\n",
       " 'inputs': 16,\n",
       " 'they': 17,\n",
       " 'long': 18,\n",
       " 'and': 19,\n",
       " 'recurrent': 20,\n",
       " 'neural': 21,\n",
       " 'rnns': 22,\n",
       " 'are': 23,\n",
       " 'data': 24,\n",
       " 'time': 25,\n",
       " 'rnn': 26,\n",
       " 'limitation': 27,\n",
       " 'short': 28,\n",
       " 'sequence': 29,\n",
       " 'problem': 30,\n",
       " 'architectures': 31,\n",
       " 'networks': 32,\n",
       " 'type': 33,\n",
       " 'designed': 34,\n",
       " 'process': 35,\n",
       " 'sequential': 36,\n",
       " 'such': 37,\n",
       " 'text': 38,\n",
       " 'or': 39,\n",
       " 'series': 40,\n",
       " 'an': 41,\n",
       " 'each': 42,\n",
       " 'output': 43,\n",
       " 'depends': 44,\n",
       " 'not': 45,\n",
       " 'just': 46,\n",
       " 'current': 47,\n",
       " 'input': 48,\n",
       " 'but': 49,\n",
       " 'also': 50,\n",
       " 'previous': 51,\n",
       " 'hidden': 52,\n",
       " 'state': 53,\n",
       " 'which': 54,\n",
       " 'allows': 55,\n",
       " 'some': 56,\n",
       " 'however': 57,\n",
       " 'standard': 58,\n",
       " 'suffer': 59,\n",
       " 'known': 60,\n",
       " 'means': 61,\n",
       " 'that': 62,\n",
       " 'while': 63,\n",
       " 'can': 64,\n",
       " 'remember': 65,\n",
       " 'recent': 66,\n",
       " 'reasonably': 67,\n",
       " 'well': 68,\n",
       " 'struggle': 69,\n",
       " 'much': 70,\n",
       " 'becomes': 71,\n",
       " 'when': 72,\n",
       " 'dependencies': 73,\n",
       " 'important—for': 74,\n",
       " 'example': 75,\n",
       " 'remembering': 76,\n",
       " 'subject': 77,\n",
       " 'sentence': 78,\n",
       " 'correctly': 79,\n",
       " 'predict': 80,\n",
       " 'final': 81,\n",
       " 'word': 82,\n",
       " 'root': 83,\n",
       " 'issue': 84,\n",
       " 'lies': 85,\n",
       " 'vanishing': 86,\n",
       " 'gradient': 87,\n",
       " 'where': 88,\n",
       " 'gradients': 89,\n",
       " 'used': 90,\n",
       " 'training': 91,\n",
       " 'become': 92,\n",
       " 'extremely': 93,\n",
       " 'small': 94,\n",
       " 'propagate': 95,\n",
       " 'backward': 96,\n",
       " 'through': 97,\n",
       " 'many': 98,\n",
       " 'steps': 99,\n",
       " 'effectively': 100,\n",
       " 'preventing': 101,\n",
       " 'early': 102,\n",
       " 'layers': 103,\n",
       " 'learning': 104,\n",
       " 'result': 105,\n",
       " 'fades': 106,\n",
       " 'away': 107,\n",
       " 'fails': 108,\n",
       " 'capture': 109,\n",
       " 'context': 110,\n",
       " 'overcome': 111,\n",
       " 'advanced': 112,\n",
       " 'like': 113,\n",
       " 'lstm': 114,\n",
       " 'gated': 115,\n",
       " 'unit': 116,\n",
       " 'gru': 117,\n",
       " 'were': 118,\n",
       " 'developed': 119,\n",
       " 'these': 120,\n",
       " 'use': 121,\n",
       " 'gating': 122,\n",
       " 'mechanisms': 123,\n",
       " 'control': 124,\n",
       " 'flow': 125,\n",
       " 'allowing': 126,\n",
       " 'important': 127,\n",
       " 'over': 128,\n",
       " 'longer': 129,\n",
       " 'periods': 130,\n",
       " 'significantly': 131,\n",
       " 'improving': 132,\n",
       " 'performance': 133,\n",
       " 'complex': 134,\n",
       " 'based': 135,\n",
       " 'tasks': 136}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index # Returns dictionary of words & their indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903f0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=[]\n",
    "for sentence in rnn.split('\\n'):   # Split text by lines\n",
    "    #print(sentence)\n",
    "    token_list=tokenizer.texts_to_sequences([sentence])[0] # Convert words to numbers\n",
    "    #print(token_list)\n",
    "    for i in range (1, len(token_list)):\n",
    "        sequence=token_list[:i+1]    # Slice sequence (e.g., [1, 2], [1, 2, 3], ...)\n",
    "        input_sequences.append(sequence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aeb8c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 21],\n",
       " [20, 21, 32],\n",
       " [20, 21, 32, 22],\n",
       " [20, 21, 32, 22, 23],\n",
       " [20, 21, 32, 22, 23, 3]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d78c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length=max([len(input_sequences) for input_sequences in input_sequences])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a192befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add padding to make all in same length\n",
    "input_sequences=np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences,maxlen=max_length, padding='pre'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc785ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20, 21, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28e64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinguish the fetures and labels\n",
    "x=input_sequences[:,:-1]\n",
    "y=input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55ed2a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ea7611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,  32,  22,  23,   3,  33,   4,  21,   5,  34,   2,  35,  36,\n",
       "        24,  37,   6,  38,  39,  25,  40,   7,  41,  26,  42,  43,  44,\n",
       "        45,  46,  12,   1,  47,  48,  49,  50,  12,   1,  51,  52,  53,\n",
       "        54,  55,   1,   5,   2,  13,  56,  14,   4,  15,  16,  58,  22,\n",
       "        59,   9,   3,  27,  60,   6,  28,  10,  14,  61,  62,  63,  17,\n",
       "        64,  65,  66,  16,  67,  68,  17,  69,   2,  13,   7,   9,  70,\n",
       "        15,   8,   1,  29,  27,  71,   3,  30,  72,  18,  10,  73,  23,\n",
       "        74,  75,  76,   1,  77,   4,   3,  78,   2,  79,  80,   1,  81,\n",
       "        82,  83,   4,  11,  84,  85,   8,   1,  86,  87,  30,  88,  89,\n",
       "        90,   8,  91,  92,  93,  94,   6,  17,  95,  96,  97,  98,  25,\n",
       "        99, 100, 101, 102, 103,   9, 104,   3, 105,   7,   9,  15,  16,\n",
       "       106, 107,  19,   1,   5, 108,   2, 109,  18,  10, 110, 111,  11,\n",
       "       112,  26,  31, 113,  18,  28,  10,  14, 114,  19, 115,  20, 116,\n",
       "       117, 118, 119,  31, 121, 122, 123,   2, 124,   1, 125,   4,   7,\n",
       "       126,   1,   5,   2,  13, 127,  24, 128, 129, 130, 131, 132, 133,\n",
       "        12, 134,  29, 135, 136])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73497ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_classes=len(tokenizer.word_index)+1\n",
    "no_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54056413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(tf.keras.utils.to_categorical(y,num_classes=no_of_classes))\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f411ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=no_of_classes,  \n",
    "                             output_dim=80, \n",
    "                             input_length=max_length-1),\n",
    "    tf.keras.layers.LSTM(100),\n",
    "    tf.keras.layers.Dense(no_of_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# To properly build the model, we can either:\n",
    "# 1. Call model.build() with input shape\n",
    "model.build(input_shape=(None, max_length-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9af80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">137</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,837</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │        \u001b[38;5;34m10,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m72,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m137\u001b[0m)            │        \u001b[38;5;34m13,837\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,197</span> (379.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,197\u001b[0m (379.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,197</span> (379.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,197\u001b[0m (379.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34a1359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.0088 - loss: 4.9198\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0688 - loss: 4.9048\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0485 - loss: 4.8851\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0592 - loss: 4.8063\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0426 - loss: 4.7118\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0806 - loss: 4.6180\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0580 - loss: 4.5358\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0725 - loss: 4.4584\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0685 - loss: 4.3613\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0889 - loss: 4.3315\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0582 - loss: 4.2638\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0841 - loss: 4.2626\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0605 - loss: 4.2020\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0580 - loss: 4.1144\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0569 - loss: 4.1273\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1068 - loss: 4.0331\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1098 - loss: 3.9611\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1206 - loss: 3.8302\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1107 - loss: 3.7525\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1110 - loss: 3.7167\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1172 - loss: 3.6334\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1603 - loss: 3.5543\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1380 - loss: 3.5067\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1468 - loss: 3.4709\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1537 - loss: 3.3666\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1979 - loss: 3.2927\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1755 - loss: 3.3035\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2307 - loss: 3.1011\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2395 - loss: 3.1221\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2572 - loss: 2.9538\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2386 - loss: 2.9829\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2463 - loss: 2.9289\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2282 - loss: 2.8835\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2696 - loss: 2.8057\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2887 - loss: 2.7744\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2927 - loss: 2.6938\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3444 - loss: 2.6656\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3392 - loss: 2.5406\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3799 - loss: 2.4999\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3621 - loss: 2.4705\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3882 - loss: 2.4365\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3784 - loss: 2.3691\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4694 - loss: 2.2877\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4755 - loss: 2.2955\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4338 - loss: 2.2081\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5238 - loss: 2.1567\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4969 - loss: 2.0803\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5173 - loss: 2.0877\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4969 - loss: 2.1463\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4826 - loss: 2.1092\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5013 - loss: 1.9935\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5812 - loss: 1.9506\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5835 - loss: 1.9234 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6162 - loss: 1.8880\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5383 - loss: 1.9166\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6279 - loss: 1.8154\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5966 - loss: 1.8136\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6528 - loss: 1.8003\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7108 - loss: 1.7086\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6230 - loss: 1.7028\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6382 - loss: 1.6919\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6520 - loss: 1.6651\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6859 - loss: 1.6584\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6904 - loss: 1.6427\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7721 - loss: 1.5928\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7821 - loss: 1.5338\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7343 - loss: 1.5524\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7631 - loss: 1.4947\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7726 - loss: 1.4508\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8046 - loss: 1.4180\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8175 - loss: 1.3942\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7958 - loss: 1.3890\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8284 - loss: 1.3778\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8699 - loss: 1.3274\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9112 - loss: 1.3220\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9062 - loss: 1.2413\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9097 - loss: 1.2685\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8700 - loss: 1.2388\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8813 - loss: 1.2357\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8965 - loss: 1.2305\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9091 - loss: 1.1779\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8836 - loss: 1.1433\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8858 - loss: 1.1725\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9306 - loss: 1.1329\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9380 - loss: 1.0919\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9195 - loss: 1.0872\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9744 - loss: 1.0301\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9394 - loss: 1.0552\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9571 - loss: 1.0133\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9604 - loss: 1.0058\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9423 - loss: 0.9849\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9588 - loss: 0.9697\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9540 - loss: 0.9749\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9632 - loss: 0.9468\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9868 - loss: 0.9115\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.8885\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9593 - loss: 0.8838\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9754 - loss: 0.9023\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.8440\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.8634\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c2a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 19]\n"
     ]
    }
   ],
   "source": [
    "input_text=\"RNN and\"\n",
    "token_list=tokenizer.texts_to_sequences([input_text])[0]\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4fc8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0  20  21]\n",
      " [  0   0   0 ...  20  21  32]\n",
      " [  0   0   0 ...  21  32  22]\n",
      " ...\n",
      " [  0   0   0 ...  12 134  29]\n",
      " [  0   0   0 ... 134  29 135]\n",
      " [  0   0   0 ...  29 135 136]]\n"
     ]
    }
   ],
   "source": [
    "token_list=tf.keras.preprocessing.sequence.pad_sequences(input_sequences,maxlen=max_length-1, padding='pre')\n",
    "print(token_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37efd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[ 32  22  23   3  33   4  21   5  34   2  35  36  24  37   6  38  39  25\n",
      "  40   7   7  26  42  43  44  45  46  12   1  47  48  49  50  12   1  51\n",
      "  52  53  54  55   1   5   2  13  56  14   4  15  16  16  22  59   9   3\n",
      "  27  60   6  28  10  14  14  62  63  17  64  65  66  16  67  68  17  69\n",
      "   2  13   7   9  70  15   8   1  29  29   3   3  30  72  18  10  73  23\n",
      "  74  75  76   1  77   4   3  78   2  79  80   1  81  82  82   4  11  84\n",
      "  85   8   1  86  87  30  88  89  90   8  91  92  93  94   6  17  95  96\n",
      "  97  98  25  99 100 101 102 103   9 104 104 105   7   9  15  16 106 107\n",
      "  19   1   5 108   2 109  18  10 110 110  11 112  26  31 113  18  28  10\n",
      "  14 114  19 115  20 116 117 118 119 119 121 122 123   2 124   1 125   4\n",
      "   7 126   1   5   2  13 127  24 128 129 130 130 132 133  12 134  29 135\n",
      " 136 136]\n"
     ]
    }
   ],
   "source": [
    "predicted=np.argmax(model.predict(token_list), axis=-1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b198391f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word, index \u001b[38;5;129;01min\u001b[39;00m tokenizer.word_index.items():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index == predicted:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mprint\u001b[39m(word)\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "        print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
